{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhATaaotWpYY"
   },
   "source": [
    "# Homework \\#10\n",
    "\n",
    "Face Tracking with KLT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaFe_Ot-ziRV"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "error",
     "timestamp": 1612557788001,
     "user": {
      "displayName": "Taeyoung Lee",
      "photoUrl": "",
      "userId": "07906618747313337531"
     },
     "user_tz": 300
    },
    "id": "XOGSROrK6oGt",
    "outputId": "201bf5ab-4d81-436e-cb82-4c62e1feaf32"
   },
   "outputs": [],
   "source": [
    "# the following two lines solved the issue of video crashing for MacOS\n",
    "# you may not need those, depending on you OS\n",
    "import matplotlib\n",
    "matplotlib.use(\"TKAgg\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.signal\n",
    "import scipy.linalg\n",
    "import mae6292.tools as mae6292\n",
    "import importlib\n",
    "\n",
    "from mae6292.imshow import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "We will perform face tracking using [https://github.com/intel-iot-devkit/sample-videos](https://github.com/intel-iot-devkit/sample-videos)\n",
    "\n",
    "### (a) Select Keypoints\n",
    "\n",
    "1. Using \n",
    "```\n",
    "    mae6292.harris_corner()\n",
    "    mae6292.select_keypoints()\n",
    "```\n",
    "select the keypoints of `frame0` with the parameters\n",
    "```\n",
    "W_harris_patch = 4\n",
    "harris_kappa = 0.08\n",
    "W_nms = 8\n",
    "N_keypoints = 1000\n",
    "```\n",
    "\n",
    "2. Convert the identififed keypoints to `2 by n` array by\n",
    "\n",
    "```\n",
    "p = np.array(keypoints, dtype='float32').T # conver list to np.array\n",
    "p = p[[1,0],:] # swap row and col\n",
    "\n",
    "```\n",
    "\n",
    "3. Show the keypoints on `frame0` using the variable `p`\n",
    "\n",
    "The results of this part will be similar with\n",
    "<img src=\"prob1a_sol.png\" width=\"500\"/>\n",
    "\n",
    "Save it into `prob1a.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "frame0 = cv2.imread('data/face000000.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "W_harris_patch = 4\n",
    "harris_kappa = 0.08\n",
    "W_nms = 8\n",
    "N_keypoints = 1000\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.imshow(frame0, cmap='gray')\n",
    "plt.plot(p0[0,:], p0[1,:], 'r+')\n",
    "\n",
    "plt.savefig('prob1a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Select Keypoints for Face\n",
    "\n",
    "1. The following function draw a yellow rectangle from the upper left corner `(u0,v0)` to the lower right corner `(u1,v1)`\n",
    "```\n",
    "def rectangle(u0, v0, u1, v1):\n",
    "    plt.plot([u0, u1],[v0, v0],'y')\n",
    "    plt.plot([u0, u1],[v1, v1],'y')\n",
    "    plt.plot([u0, u0],[v0, v1],'y')\n",
    "    plt.plot([u1, u1],[v0, v1],'y')\n",
    "```\n",
    "Adjust the value of `(u0,v0),(u1,v1)` so that the rectangle encloses the face.\n",
    "\n",
    "2. Identify the keypoints within the about rectangle, and save it into `p0_face`. \n",
    "\n",
    "3. Show the bounding box for the face and the features in the box.\n",
    "\n",
    "The results of this part will be similar with\n",
    "\n",
    "<img src=\"prob1b_sol.png\" width=\"500\"/>\n",
    "\n",
    "Save it into `prob1b.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle(u0, v0, u1, v1):\n",
    "    plt.plot([u0, u1],[v0, v0],'y')\n",
    "    plt.plot([u0, u1],[v1, v1],'y')\n",
    "    plt.plot([u0, u0],[v0, v1],'y')\n",
    "    plt.plot([u1, u1],[v0, v1],'y')\n",
    "\n",
    "# 1. arbitrary values    \n",
    "u0, v0 = 200, 100\n",
    "u1, v1 = 400, 300\n",
    "\n",
    "# 2. Identify keypoints in the box\n",
    "\n",
    "# empty container\n",
    "p0_face = np.empty((2,0), dtype='float32')\n",
    "# repeat for each keypoint\n",
    "for i in range(p0.shape[1]):\n",
    "    ## YOUR CODE HERE:\n",
    "    ## write if statement for the case that the i-th keypoint (p[0,i], p[1,i]) belongs to the box\n",
    "    if ##(write conditions here)\n",
    "        p0_face = np.append(p0_face, p0[:,i].reshape(2,1), axis=1)\n",
    "\n",
    "# 3. Plot box and feaatures, adjust (u0,v0), (u1,v1) manually        \n",
    "plt.figure(dpi=120)\n",
    "plt.imshow(frame0, cmap='gray')\n",
    "rectangle(u0,v0, u1,v1)\n",
    "plt.plot(p0_face[0,:], p0_face[1,:], 'r+')\n",
    "\n",
    "plt.savefig('prob1b.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "### (a)\n",
    "\n",
    "Now, we are going to track the features within the bounding box, using KLT. \n",
    "\n",
    "1. Load `frame1`.\n",
    "2. Tack the above face features `p0_face` from `frame0` and `frame` using\n",
    "\n",
    "```\n",
    "p1, index_track = mae6292.KLT(frame0, frame1, p0_face, W = 7, tol_bidir = 10, display = False)\n",
    "p1_face = p1[:,index_track]\n",
    "\n",
    "```\n",
    "\n",
    "3. Determine `(u0,v0), (u1,v1)` for the new bounding box enclosing `p1_face`. For example\n",
    "```\n",
    "u0 = np.amin(p1_face[0,:])\n",
    "```\n",
    "4. Show the new bounding box for the face and the features in `frame1`\n",
    "\n",
    "\n",
    "The results of this part will be similar with\n",
    "<img src=\"prob2a_sol.png\" width=\"500\"/>\n",
    "\n",
    "Save it into `prob2a.png`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = cv2.imread('data/face000001.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "p1, index_track = mae6292.KLT(frame0, frame1, p0_face, W = 7, tol_bidir = 1, display = False)\n",
    "p1_face = p1[:,index_track]\n",
    "\n",
    "u0 = np.amin(p1_face[0,:])\n",
    "\n",
    "## YOUR CODE HERE\n",
    "## to define v0, (u1,v1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(frame0, cmap='gray')\n",
    "rectangle(u0,v0, u1,v1)\n",
    "plt.plot(p1_face[0,:], p1_face[1,:], 'r+')\n",
    "\n",
    "plt.savefig('prob2a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "Repeat the above tracking up to the first 100 frames. The last plot will be similar with\n",
    "\n",
    "\n",
    "<img src=\"prob2b_sol.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "Save the last plot as `prob2b.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw figures within jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "frame_pre = frame0\n",
    "p_face_pre = p0_face\n",
    "    \n",
    "for i in range(1,100):\n",
    "    frame = cv2.imread(\"data/face{:06d}.png\".format(i),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ## YOUR CODE HERE\n",
    "    # Track `p_face_pre` from frame_pre to frame\n",
    "\n",
    "    # choose (u0, v0), (u1, v1)\n",
    "\n",
    "    \n",
    "    # show results\n",
    "    plt.figure(dpi=50)\n",
    "    plt.imshow(frame, cmap='gray')\n",
    "    rectangle(u0,v0, u1,v1)\n",
    "    plt.plot(p_face[0,:], p_face[1,:], 'r+')\n",
    "\n",
    "    p_face_pre = p_face\n",
    "    frame_pre = frame\n",
    "\n",
    "plt.savefig('prob2b.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Here we will read and save videos using OpenCV. Read the tutorial [Getting Started with Videos](https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html). \n",
    "\n",
    "The following code will \n",
    "1. read the each frame of the video\n",
    "2. draw an arbitrary box\n",
    "3. display each frame\n",
    "4. save the video into `prob2c.mp4`\n",
    "\n",
    "Modify codes within the lines closed by `#####` such that the results of 2.(b) is saved into a video file, `prob2c.mp4`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a new window for plot\n",
    "%matplotlib tk\n",
    "\n",
    "# open a video file to read\n",
    "video_read = cv2.VideoCapture('head-pose-face-detection-female.mp4')\n",
    "\n",
    "# get frame size and fps (number of frames per second)\n",
    "width = int(video_read.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video_read.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video_read.get(cv2.CAP_PROP_FPS)\n",
    "size = (width, height)\n",
    "\n",
    "# open a video file to save\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_save = cv2.VideoWriter('prob2c.mp4', codec, fps, size)\n",
    "\n",
    "# to initiate the iteration, the first frame is saved to `frame_pre`\n",
    "ret, frame_color = video_read.read() # color frame\n",
    "frame_pre = cv2.cvtColor(frame_color, cv2.COLOR_BGR2GRAY) # grayscale frame\n",
    "p_face_pre = p0_face # face features for the first frame\n",
    "\n",
    "# repeat for each frame\n",
    "for i in range(1,300):    \n",
    "\n",
    "    # read a new frame\n",
    "    ret, frame_color = video_read.read() # color frame\n",
    "    frame = cv2.cvtColor(frame_color, cv2.COLOR_BGR2GRAY) #grayscale frame\n",
    "    \n",
    "    ############################################\n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    # 1. Track p_face_pre from frame_pre to frame, save the tracked frame into p_face\n",
    "\n",
    "    \n",
    "    \n",
    "    # 2. Compute (u0,v0), (u1,v1) for the new bounding box using p_face\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # 3. Draw a rectangle on the color frame\n",
    "    cv2.rectangle(frame_color, (int(u0),int(v0)), (int(u1),int(v1)), (0, 255,255))     \n",
    "    \n",
    "    # 4. current frame and features are saved into pre-frame and pre-feataures, for the next iteration\n",
    "    frame_pre = frame\n",
    "    p_face_pre = p_face\n",
    "    #############################################   \n",
    "\n",
    "#    show the frame \n",
    "    cv2.imshow('frame',frame_color)\n",
    "    if cv2.waitKey(1) == ord('q'): # stop if \"q\" is pressed\n",
    "        break   \n",
    "\n",
    " #   save the frame\n",
    "    video_save.write(frame_color)\n",
    "\n",
    "# release video files       \n",
    "video_read.release()\n",
    "video_save.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Record a short video of yourself and perform face tracking using the above code. Save it into `prob3.mp4`\n",
    "\n",
    "1. Your video can be about 5 seconds or so.\n",
    "2. Try to reduce the resolution. For example, the resolution of the above video is `(768, 432)`\n",
    "3. You may need to tune the following parameters for Harris feature detector\n",
    "```\n",
    "W_harris_patch = 4\n",
    "harris_kappa = 0.08\n",
    "W_nms = 8\n",
    "N_keypoints = 1000\n",
    "```\n",
    "and the following parameters `W` and `tol_bidir` in KLT\n",
    "\n",
    "```\n",
    "p, index_track = mae6292.KLT(frame_pre, frame, p_face_pre, W = 7, tol_bidir = 10, display = False)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How To Submit\n",
    "\n",
    "Attach\n",
    "\n",
    "1.  `prob1a.png`, `prob1b.png`\n",
    "2.  `prob2a.png`, `prob2b.png`, `prob2c.mp4`\n",
    "3.  `prob3.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YaFe_Ot-ziRV"
   ],
   "name": "image_filtering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
